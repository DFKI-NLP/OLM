{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from xbert.engine import Engine, weight_of_evidence, difference_of_log_probabilities, calculate_correlation\n",
    "from xbert import InputInstance, Config\n",
    "from xbert.visualization import visualize_relevances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segtok.tokenizer import web_tokenizer\n",
    "\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification  #, glue_convert_examples_to_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_DEVICE = 0 # or -1 if no GPU is available\n",
    "\n",
    "MODEL_NAME = \"roberta-large-mnli\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = RobertaForSequenceClassification.from_pretrained(MODEL_NAME).to(CUDA_DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNLI_DATASET_PATH = \"../data/glue_data/MNLI/\"\n",
    "MNLI_IDX2LABEL = {0: 'contradiction', 1: 'neutral', 2: 'entailment'}\n",
    "MNLI_LABEL2IDX = {v: k for k, v in MNLI_IDX2LABEL.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "def read_mnli_dataset(path: str) -> List[Tuple[List[str], List[str], str]]:\n",
    "    dataset = []\n",
    "    with open(path) as fin:\n",
    "        fin.readline()\n",
    "        for index, line in enumerate(fin):\n",
    "            tokens = line.strip().split('\\t')\n",
    "            sent1, sent2, target = tokens[8], tokens[9], tokens[-1]\n",
    "            dataset.append((sent1, sent2, target))\n",
    "            \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def dataset_to_input_instances(dataset: List[Tuple[List[str], List[str], str]]) -> List[InputInstance]:\n",
    "    input_instances = []\n",
    "    for idx, (sent1, sent2, _) in enumerate(dataset):\n",
    "        instance = InputInstance(id_=idx, sent1=web_tokenizer(sent1), sent2=web_tokenizer(sent2))\n",
    "        input_instances.append(instance)\n",
    "        \n",
    "    return input_instances\n",
    "\n",
    "\n",
    "def get_labels(dataset: List[Tuple[List[str], List[str], str]]) -> List[str]:\n",
    "    return [label for _, _, label in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_instance, model, tokenizer, cuda_device):\n",
    "    input_ids = tokenizer.encode(text=input_instance.sent1.tokens,\n",
    "                                 text_pair=input_instance.sent2.tokens,\n",
    "                                 add_special_tokens=True,\n",
    "                                 return_tensors=\"pt\").to(cuda_device)\n",
    "    \n",
    "    logits = model(input_ids)[0]\n",
    "    return F.softmax(logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_mnli_dataset(os.path.join(MNLI_DATASET_PATH, \"dev_matched.tsv\"))\n",
    "input_instances = dataset_to_input_instances(dataset)\n",
    "labels = get_labels(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batcher(batch_instances):\n",
    "    true_label_indices = []\n",
    "    probabilities = []\n",
    "    for instance in batch_instances:\n",
    "        idx = instance.id\n",
    "        true_label_idx = MNLI_LABEL2IDX[labels[idx]]\n",
    "        true_label_indices.append(true_label_idx)\n",
    "        probs = predict(instance, model, tokenizer, CUDA_DEVICE)[0]\n",
    "        probabilities.append(probs[true_label_idx].item())\n",
    "    \n",
    "    return probabilities\n",
    "    \n",
    "\n",
    "config_unk = Config.from_dict({\n",
    "    \"strategy\": \"unk_replacement\",\n",
    "    \"batch_size\": 128,\n",
    "    \"unk_token\": \"___UNK___\"\n",
    "})\n",
    "\n",
    "config_resample = Config.from_dict({\n",
    "    \"strategy\": \"bert_lm_sampling\",\n",
    "    \"cuda_device\": 0,\n",
    "    \"bert_model\": \"bert-base-uncased\",\n",
    "    \"batch_size\": 128,\n",
    "    \"n_samples\": 100,\n",
    "    \"verbose\": False\n",
    "})\n",
    "\n",
    "unknown_engine = Engine(config_unk, batcher)\n",
    "resample_engine = Engine(config_resample, batcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "instance_idx = 0\n",
    "n = 5\n",
    "\n",
    "unk_occluded_instances, unk_instance_probabilities = unknown_engine.run(input_instances[instance_idx: instance_idx+n])\n",
    "res_occluded_instances, res_instance_probabilities = resample_engine.run(input_instances[instance_idx: instance_idx+n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_relevances_difference = unknown_engine.relevances(unk_occluded_instances, unk_instance_probabilities)\n",
    "res_relevances_difference = resample_engine.relevances(res_occluded_instances, res_instance_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_true = labels[instance_idx: instance_idx+n]\n",
    "labels_pred = [MNLI_IDX2LABEL[predict(instance, model, tokenizer, CUDA_DEVICE)[0].argmax().item()] for instance in input_instances[instance_idx: instance_idx+n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(visualize_relevances(input_instances[instance_idx: instance_idx+n], unk_relevances_difference, labels_true, labels_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(visualize_relevances(input_instances[instance_idx: instance_idx+n], res_relevances_difference, labels_true, labels_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_correlation(unk_relevances_difference, res_relevances_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
