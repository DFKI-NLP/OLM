{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from xbert_tasks.predictor_utils import load_predictor\n",
    "\n",
    "from xbert_tasks.classification.models.text_classifier import TextClassifier\n",
    "from xbert_tasks.classification.predictors.text_classifier_predictor import TextClassifierPredictor\n",
    "from xbert_tasks.classification.dataset_readers.sst2_dataset_reader import Sst2DatasetReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xbert.occlusion import Engine, weight_of_evidence, difference_of_log_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_relevances(inputs, relevances, labels_true = None, labels_pred = None, font_size=5):\n",
    "    def rgba(relevance):\n",
    "        if relevance >= 0:\n",
    "            return f\"rgba(255, 0, 0, {relevance})\"\n",
    "        else:\n",
    "            return f\"rgba(0, 0, 255, {abs(relevance)})\"\n",
    "        \n",
    "    def color(relevance):\n",
    "        if relevance > 0.8:\n",
    "            return \"white\"\n",
    "        else:\n",
    "            return \"black\"\n",
    "        \n",
    "    visualized_inputs = []\n",
    "    for i, (input_id, tokens) in enumerate(inputs):\n",
    "        tokens_relevance = relevances[input_id]\n",
    "        max_relevance = max(np.abs(list(tokens_relevance.values())))\n",
    "        norm_tokens_relevance = {idx: r / max_relevance for idx, r in tokens_relevance.items()}\n",
    "        \n",
    "        html_tokens = []\n",
    "        for idx, token in enumerate(tokens):\n",
    "            relevance = norm_tokens_relevance[idx]\n",
    "            html_token = f'<span style=\"color:{color(relevance)}; background-color:{rgba(relevance)};\">{token}</span>'\n",
    "            html_tokens.append(html_token)\n",
    "        \n",
    "        if labels_true is not None:\n",
    "            correct = \"\"\n",
    "            if labels_pred is not None:\n",
    "                correct = \"&#10004;\" if labels_true[i] == labels_pred[i] else \"&#10006;\"\n",
    "                \n",
    "            prefix = '<span style=\"color:black; background-color:rgba(255, 255, 0, 0.6);\">' \\\n",
    "                + f'{labels_true[i]} {correct} {max_relevance:.2f}</span>:   '\n",
    "        else:\n",
    "            prefix = \"\"\n",
    "            \n",
    "        visualized_input = f'<font size=\"{font_size}\">' + prefix + \" \".join(html_tokens) + '</font>'\n",
    "        \n",
    "        visualized_inputs.append(visualized_input)\n",
    "            \n",
    "    return HTML(\"</br>\".join(visualized_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_DEVICE = 0 # or -1 if no GPU is available\n",
    "\n",
    "MODEL_DIR = \"~/Downloads/xbert_sst2/\"\n",
    "PREDICTOR_NAME = \"text_classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = load_predictor(MODEL_DIR, PREDICTOR_NAME, CUDA_DEVICE, archive_filename=\"model.tar.gz\", weights_file=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SST_DATASET_PATH = \"~/Downloads/SST-2/\"\n",
    "\n",
    "instances = predictor._dataset_reader.read(SST_DATASET_PATH + \"dev.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batcher(batch_candidates):\n",
    "    label2idx = predictor._model.vocab.get_token_to_index_vocabulary(\"labels\")\n",
    "    \n",
    "    true_label_indices = []\n",
    "    batch_dicts = []\n",
    "    for candidate in batch_candidates:\n",
    "        idx = candidate.id\n",
    "        true_label_idx = label2idx[instances[idx].fields[\"label\"].label]\n",
    "        true_label_indices.append(true_label_idx)\n",
    "        batch_dicts.append(dict(text=candidate.tokens))\n",
    "    \n",
    "    results = predictor.predict_batch_json(batch_dicts)\n",
    "    \n",
    "    return [result[\"class_probabilities\"][tl_idx] for (result, tl_idx) in zip(results, true_label_indices)]\n",
    "    \n",
    "\n",
    "params = {\n",
    "    \"cuda_device\": 0,\n",
    "    \"bert_model\": \"bert-base-uncased\",\n",
    "    \"batch_size\": 128,\n",
    "    \"n_samples\": 100,\n",
    "    \"verbose\": False\n",
    "}\n",
    "\n",
    "engine = Engine(params, batcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs = [(idx, [t.text for t in instance.fields[\"tokens\"].tokens]) for idx, instance in enumerate(instances)]\n",
    "#labels_true = [instance.fields[\"label\"].label for instance in instances]\n",
    "#labels_pred = [predictor.predict_instance(instance)[\"label\"] for instance in instances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_idx = 0\n",
    "n = 100\n",
    "inputs = [(idx, [t.text for t in instance.fields[\"tokens\"].tokens]) for idx, instance in zip(range(instance_idx, instance_idx+n), instances[instance_idx: instance_idx+n])]\n",
    "labels_true = [instance.fields[\"label\"].label for instance in instances[instance_idx: instance_idx+n]]\n",
    "labels_pred = [predictor.predict_instance(instance)[\"label\"] for instance in instances[instance_idx: instance_idx+n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.run(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevances_evidence = engine.relevances(scoring_method=weight_of_evidence)\n",
    "relevances_difference = engine.relevances()\n",
    "relevances_difference_log = engine.relevances(scoring_method=difference_of_log_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_relevances(inputs, relevances_evidence, labels_true, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_relevances(inputs, relevances_difference, labels_true, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_relevances(inputs, relevances_difference_log, labels_true, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
